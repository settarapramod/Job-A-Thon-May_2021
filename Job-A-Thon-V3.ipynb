{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics   \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV \n",
    "import lightgbm as lgb\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import time\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_s3TEQDk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statisctics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We Found 29325 Missing Values in the column Credit_Product**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So let's fill those missing values Using KNN Imputer and applying Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=3)\n",
    "SC = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data.drop(axis=1,labels=['ID'])\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding all Categorical Attributes using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new.iloc[:,:].values\n",
    "label_encoder = LabelEncoder()\n",
    "x[:,0] = label_encoder.fit_transform(x[:,0])\n",
    "\n",
    "x[:,2] = label_encoder.fit_transform(x[:,2])\n",
    "x[:,3] = label_encoder.fit_transform(x[:,3])\n",
    "x[:,4] = label_encoder.fit_transform(x[:,4])\n",
    "x[:,6] = label_encoder.fit_transform(x[:,6])\n",
    "x[:,-2] = label_encoder.fit_transform(x[:,-2])\n",
    "\n",
    "x[0:5]\n",
    "print('After Encoding',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =imputer.fit_transform(x)\n",
    "print('After Imputing',x.shape)\n",
    "\n",
    "X = SC.fit_transform(x[:,[0,1,2,3,4,5,6,8]])\n",
    "print('After Standard Scaling',X.shape)\n",
    "Y = x[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data for Train, Test and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.10, random_state=43)\n",
    "X_val, X_test, y_val, y_test = train_test_split( X_test, y_test, test_size=0.5, random_state=43)\n",
    "\n",
    "print ('Train set     :', X_train.shape,  y_train.shape)\n",
    "print ('Validation set:', X_val.shape,  y_val.shape)\n",
    "print ('Test set      :', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6,n_estimators=10000, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample):\n",
    "        params = {'application':'binary', 'metric':'auc'}\n",
    "        params['learning_rate'] = max(min(learning_rate, 1), 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['max_bin'] = int(round(max_depth))\n",
    "        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "        \n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "     \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.01, 1.0),\n",
    "                                            'num_leaves': (24, 80),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 30),\n",
    "                                            'max_bin':(20,90),\n",
    "                                            'min_data_in_leaf': (20, 80),\n",
    "                                            'min_sum_hessian_in_leaf':(0,100),\n",
    "                                           'subsample': (0.01, 1.0)}, random_state=200)\n",
    "\n",
    "    \n",
    "    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n",
    "    \n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    model_auc=[]\n",
    "    for model in range(len( lgbBO.res)):\n",
    "        model_auc.append(lgbBO.res[model]['target'])\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X, Y, init_round=10, opt_round=10, n_folds=5, random_seed=42,n_estimators=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\n",
    "opt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\n",
    "opt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf']))\n",
    "opt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\n",
    "opt_params[1]['objective']='binary'\n",
    "opt_params[1]['metric']='auc'\n",
    "opt_params[1]['is_unbalance']=True\n",
    "opt_params[1]['boost_from_average']=False\n",
    "opt_params=opt_params[1]\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scores = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=30, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = lgb.LGBMClassifier(bagging_fraction = 0.8015970276069816,\n",
    " feature_fraction= 0.7006594439332303,\n",
    " learning_rate= 0.14145368629183372,\n",
    " max_bin= 86,\n",
    " max_depth= 29,\n",
    " min_data_in_leaf= 65,\n",
    " min_sum_hessian_in_leaf= 61.044672381045665,\n",
    " num_leaves= 25,\n",
    " subsample= 0.5856822903390296,\n",
    " objective= 'binary',\n",
    " metric= 'auc',\n",
    " is_unbalance= True,\n",
    " boost_from_average= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(x): \n",
    "    print(\"Training data index: \", train_index, \"\\n\") \n",
    "    print(\"Test data index: \", test_index) \n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], Y[train_index], Y[test_index] \n",
    "    model.fit(X_train, y_train) \n",
    "    my_scores.append(model.score(X_test, y_test)) \n",
    "    model.fit(X_train, y_train) \n",
    "    my_scores.append(model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean value is\" ) \n",
    "print(np.mean(my_scores)) \n",
    "#or \n",
    "cross_val_score(model, X, Y, cv=10) \n",
    "#(or) \n",
    "cross_val_predict(model, X, Y, cv=10, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(bagging_fraction = 0.9280786928822388,\n",
    " feature_fraction= 0.5869250335390612,\n",
    " learning_rate= 0.11437976620936573,\n",
    " max_bin= 88,\n",
    " max_depth= 24,\n",
    " min_data_in_leaf= 61,\n",
    " min_sum_hessian_in_leaf= 32.93481038105413,\n",
    " num_leaves= 25,\n",
    " subsample= 0.805623782185316,\n",
    " objective= 'binary',\n",
    " metric= 'auc',\n",
    " is_unbalance= True,\n",
    " boost_from_average= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {'max_bin': range(20,100,2),\n",
    " 'max_depth': range(5,100,2),\n",
    " 'min_data_in_leaf': range(10,100,2)}\n",
    "gsearch1 = GridSearchCV(estimator =model, param_grid = param_test1,scoring='roc_auc',n_jobs=4,cv=5)\n",
    "gsearch1.fit(x,Y)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM=lgb.LGBMClassifier(bagging_fraction = 0.9280786928822388,\n",
    " feature_fraction= 0.5869250335390612,\n",
    " learning_rate= 0.11437976620936573,\n",
    " max_bin= 88,\n",
    " max_depth= 24,\n",
    " min_data_in_leaf= 61,\n",
    " min_sum_hessian_in_leaf= 32.93481038105413,\n",
    " num_leaves= 25,\n",
    " subsample= 0.805623782185316,\n",
    " objective= 'binary',\n",
    " metric= 'auc',\n",
    " is_unbalance= True,\n",
    " boost_from_average= False).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred=LGBM.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy: ',roc_auc_score(y_train, LGBM.predict_proba(X_train)[:,1]))\n",
    "print('Validation Accuracy: ',roc_auc_score(y_val, lgbm_pred[:,1]))\n",
    "print('Total Data Accuracy: ',roc_auc_score(Y, LGBM.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Data Accuracy: ',roc_auc_score(y_test, LGBM.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = RFC.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy: ',roc_auc_score(y_train, RFC.predict_proba(X_train)[:,1]))\n",
    "print('Validation Accuracy: ',roc_auc_score(y_val, rfc_pred[:,1]))\n",
    "print('Total Data Accuracy: ',roc_auc_score(Y, RFC.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(learning_rate =0.3, n_estimators=115, max_depth=7,min_child_weight=6,\n",
    "                        gamma=0.1,colsample_bytree=0.8,objective= 'binary:logistic',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = XGB.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy: ',roc_auc_score(y_train, XGB.predict_proba(X_train)[:,1]))\n",
    "print('Validation Accuracy: ',roc_auc_score(y_val, xgb_pred[:,1]))\n",
    "print('Total Data Accuracy: ',roc_auc_score(Y, XGB.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_mSzZ8RL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.drop(axis=1,labels=['ID'])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = test_data.iloc[:,:].values\n",
    "label_encoder = LabelEncoder()\n",
    "xt[:,0] = label_encoder.fit_transform(xt[:,0])\n",
    "\n",
    "xt[:,2] = label_encoder.fit_transform(xt[:,2])\n",
    "xt[:,3] = label_encoder.fit_transform(xt[:,3])\n",
    "xt[:,4] = label_encoder.fit_transform(xt[:,4])\n",
    "xt[:,6] = label_encoder.fit_transform(xt[:,6])\n",
    "xt[:,-1] = label_encoder.fit_transform(xt[:,-1])\n",
    "\n",
    "xt[0:5]\n",
    "xt_filled =imputer.fit_transform(xt)\n",
    "xt = SC.fit_transform(xt[:,[0,1,2,3,4,5,6,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = LGBM.predict_proba(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = test[['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.insert(1, 'Is_Lead', yhat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_csv('Trail24.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
